# 存储器层次结构

存储器系统是一个层次的结构，包括：

- 1.CUP寄存器
- 2.靠近CUP的高速缓存存储器
- 3.主存储器
- 4.磁盘
- 5.通过网络连接的其他设备

每一层都作为下一层的`缓存`区域

## 存储技术

### 随机访问存储器

随机访问存储器（Random-Access Memory RAM）分成两类：静态（SRAM）和动态（DRAM）

- 1.SRAM

SRAM用作`高速缓存存储器`，可以在CPU上也可以在片下，它将每个位存储在一个`双稳态`的存储器单元里，每个单元由`6个晶体管`构成

由于双稳态的特性，只要有电，SRAM就会`永远`保持它的值

通常SRAM不会超过`几兆`字节

- 2.DRAM

DRAM用作`主存`（内存）以及图形系统的帧缓冲区，每个位由`一个晶体管`和`一个电容`构成

DRAM是`不稳定`的，当电容电压被扰乱之后，就不能恢复了

DRAM芯片封装在`内存模块`中，插到主板的扩展槽上，现代内存模块（以Core i7为例）使用240个引脚的`双列直插内存模块`，以64位为块与`内存控制器`互相传输数据

### 非易失性存储器

SRAM和DRAM在断电时会失去信息，他们是易失的

`只读存储器（Read-Only Memory）`是非易失的

根据能够被重编程的次数和重编程的机制将ROM分类：

PROM只能被编程`一次`，可擦写可编程EPROM通过紫外线照射窗口擦除，重编程次数可达1000次，电子可擦除EEORPM能够达到100000次

`闪存`是基于EEPROM的，固态硬盘是基于闪存的


### 磁盘

磁盘由`盘片`构成，每个盘片有两个`表面`，每个表面有一组被称为`磁道`的同心圆组成，每个磁道被划分为一组`扇区`

通常用`柱面`来描述多个盘片驱动器的构造

磁盘用`读/写头`来读写表面上的位，其访问时间主要分为：`寻道时间`、`旋转时间`和`传送时间`，延时主要发生在寻道和旋转延时

磁盘格式化时，会预留一些`备用`的柱面，所以实际的容量会比标称的容量小

- 通用串行总线（Universal Serial Bus USB）

- 内存映射I/O：地址空间中有一块地址是为与I/O设备通信保留的，每个地址称为一个`I/O端口`

- 访问磁盘

    - 1.CPU发起一个磁盘读
    - 2.磁盘读取扇区，并执行向主存的DMA（Direct Memory Access）传送
    - 3.磁盘控制器向CPU发送中断信号来通知CPU传输完成

### 固态硬盘

固态硬盘（Solid State Disk）是基于闪存的存储技术

一个SSD封装由一个或多个`闪存芯片`和`闪存翻译层`组成

一个闪存由多个`块`组成，一个块由多个`页`组成

### 存储器层次结构

上一层是下一层的缓存

每一层的数据被划分成连续的数据对象`块`

第k层的存储器被划分为比k+1层更少的块的集合

当程序需要k+1层的某个对象d时，如果d刚好缓存在第k层中，称为`缓存命中`，否则第k层需要向第k+1层读取，称为`缓存不命中`

当第k层的缓存满时，就需要用k+1层的块`覆盖`现存的一个块，需要由`替换策略`来决定替换哪一个块

### 高速缓存

可以依次划分为`组`、`行`、`块`

尽量使不同元素的地址映射到不同的组中，来避免冲突

替换策略：最不常使用 Least-Frequently Used `LFU`，最近最少使用 Least-Recently Used `LRU`

写缓存时，有两种方法：

- 1.直写，将已经缓存的字w`立即`写到下一层

- 2.写回，尽可能地推迟更新，直到替换算法将要`驱逐`这个块，它能显著地减少总线流量，但实现起来更复杂

#### 层次结构

以Core i7为例，CPU芯片有4个核，每个核有自己`私有的`L1 i-cache（指令缓存）和L2 d-cache（数据缓存）和L2统一高速缓存，所有的核`共享`L3统一的高速缓存

## 局部性

具有局部性的程序倾向于引用`临近于`其它`最近引用过`的数据项的数据项

- 时间局部性：被引用过一次的内存位置可能在不久的将来`再被多次引用`

- 空间局部性：如果一个内存位置被引用了一次，那么程序可能在不久的将来引用`它附近`的一个内存位置

## 链接

链接是将各种代码和数据片段收集并组合成为一个`单一文件`的过程

链接可以执行与`编译时`、`加载时`和`运行时`，通过`链接器`自动执行

c语言编译的过程：源程序`main.c`，ASCII码中间文件`main.i`，ASCII汇编语言文件`main.s`，可重定位目标文件`main.o`，可执行文件`prog`

### 静态链接

静态链接器以一组`可重定位目标文件`和`命令行参数`为输入，生成一个完全链接的、可以加载和运行的`可执行文件`为输出

输入的可重庆薇目标文件由各种不同的`代码`和`数据节`组成

链接器有两个最主要任务：

- 1.符号解析：目标文件中符号对应定义的变量，符号解析的目的是将符号`引用`和符号`定义`关联起来

- 2.重定位：将每个符号定义与一个`内存位置`关联起来

### 动态链接共享库

共享库是一个目标模块，在运行或加载时，可以加载到`任意的`内存地址（`位置无关代码`），并和一个在内存中的`程序链接起来`，这个过程称为`动态链接`

共享库在Linux中通常用.so后缀表示

对于一个给定的文件系统，每一个库`只有一个`.so文件，所有引用该库的可执行目标文件`共享`这个.so文件中的代码和数据，而不需像静态库那样将内容复制到可执行文件中，这样减少了内存开销

### 加载可执行目标文件

运行可执行文件时，通过某个驻留在存储器中称为`加载器`的操作系统代码来执行它

任何Linux程序都可以通过调用execve程序来调用加载器，将程序复制到`内存`并执行


# 异常控制流

## 异常

在处理器中，程序计数器有一个值的序列a1,a2...ak,ak+1，每个ak是相应的指令Ik的地址，从ak到ak+1的过渡称为`控制转移`，一个控制转移序列称为处理器的`控制流`

现代系统通过是控制流发生`突变`来响应事件，将这些突变称为`异常控制流（Exceptional Control Flow ECF）`

ECF是操作系统用来实现I/O、进程和虚拟内存的基本机制，应用程序通过`陷阱`或者`系统调用`的ECF形式向操作系统请求服务

### 异常的处理

系统中为每一类型的异常都分配了唯一的`异常号`，并存放在一张称为`异常表`的跳转表中

程序运行时，当系统检测到一个事件，并确定其异常号k，将会执行`间接过程调用`，同过异常表的表目k，转到相应的处理程序

异常处理程序运行在`内核模式`下，它们对所有的系统资源都有`完全的访问权限`

### 异常的分类

异常可以分为4类：中断、陷阱、故障和终止

- 1.中断

中断是`异步`发生的，是来自处理器外部的`I/O设备的信号`的结果，处理结束返回时总是返回到`下一条指令`

除了中断以外的其他三种异常都是`同步`发生的，是执行`当前指令`的结果

- 2.陷阱和系统调用

陷阱是`有意`的异常，是执行一条指令的结果，它也返回到`下一条指令`

陷阱最重要的用途是提供一个像过程一样的接口，称为`系统调用`，用于用户程序对`内核服务`的访问

当用户想要请求内核服务n时，将执行`syscall n`指令，它会导致一个到异常处理程序的陷阱

- 3.故障

故障由`错误情况`引起，当故障发生时，处理器将控制转移给故障处理程序，如果它能`修正`这个故障，就将控制返回给引起故障的指令（原指令）并`重新执行`它，否则处理程序返回到内核中的`abort`例程，它将`终止`引起故障的应用程序

- 4.终止

终止是不可恢复的`致命错误`造成的结果，通常是硬件错误，终止处理程序直接将控制返回给abort例程，终止这个应用程序

## 进程

进程可以定义为一个`执行中程序的实例`，系统中的每个程序都运行在某个进程的`上下文`中，上下文是由`程序正确运行所需的状态`组成的

进程为应用程序气筒两个关键`抽象`：

- 1.一个独立的逻辑控制流，它提供一个假象，好象每个程序`独占处理器`

- 2.一个私有的地址空间，它提供一个假象，好象每个程序`独占内存系统`

### 逻辑控制流

进程是`轮流使用`处理器的，每个进程执行它的流的一部分，然后被`抢占`（暂时挂起），然后轮到其它进程

### 并发流

一个逻辑流的执行在`时间上`与另一个流重叠，称为`并发流`

多个流并发的执行的现相称为`并发`，一个进程和其它进程轮流运行的概念称为`多任务`，一个进程执行它的控制流的一部分的每一时间称为`时间片`，多任务也成为`时间分片`

如果两个流并发的运行在不同的处理器或计算机上，称它们为`并行流`

### 私有地址空间

一台n位的计算机上，地址空间是`2^n`个可能地址的集合，进程为每个应用程序提供它自己的`私有地址空间`，这个空间中某个地址相`关联的内存`是不能被其它进程读写的

### 用户模式与内核模式

处理器需要提供一种机制来限制一个应用可以执行的指令以及它可以访问到地址空间

通常是使用某个`控制寄存器`的一个`模式位`来实现的，设置了模式位时，进程运行在`内核模式`中，内核模式运行的进程可以访问任何地址空间，执行任何指令；

反之则运行在`用户模式`中，用户模式的程序不允许执行特权指令，也不允许直接引用内核区的代码和数据，用户程序必须通过`系统调用接口`间接的访问内核代码和数据

进程从用户模式切换到内核模式的唯一方法是通过诸如中断、故障或陷入系统调用这样的`异常`

### 上下文切换

内核为每个进程维持一个上下文，上下文是内核重新启动一个被抢占的进程所需的`状态`

内核可以决定是否抢占当前进程并恢复一个其它进程，这种策略称为`调度`，通过`调度器`完成

## 进程控制

每个进程都有唯一的正数进程ID（PID）

### 创建和终止进程

进程总是处于以下三种状态之一：

- 1.运行，运行中的进程要么在CPU上`执行`，要么在`等待被执行`且最终会被内核调度

- 2.停止，停止的进程被`挂起`，且不会被调度，直到收到一个SIGCONT信号，进程再次开始运行

- 3.终止，进程永远停止了，终止可能由三种原因引起：收到终止进程的`信号`、从`主程序返回`或调用`exit函数`

父进程通过调用`fork函数`创建一个新的运行的子进程

- 新创建的子进程几乎与父进程完全相同，它们最大的区别是具`有不同的PID`

- fork函数直被调用一次，却返回`两次`，一次是在调用父进程中，一次是在新创建的子进程中，在父进程中，fork返回`子进程的PID`，再子进程中fork返回`0`，这样就可以`区分`程序是在父进程还是在子进程中执行

- 父进程与子进程是`并发`执行的，具有`相同但独立的地址空间`，并`共享文件`

### 回收子进程

当一个子进程终止时，内核并不是立即将它清除，而是将进程保持在`已终止`的状态中，直到被它的父进程`回收`

如果一个父进程终止了，内核会安排`init进程`成为它的孤儿进程的养父，init进程的PID为`1`，是系统启动时内核创建的，它`不会终止`，是所有进程的`祖先`

### 加载并运行程序

execve函数在当前进程的上下文中加载并运行一个新程序

fork与execve的区别：

- 1.fork调用一次返回两次，execve调用一次但`不返回`

- 2.fork在新的子进程中运行与父进程相同的程序，子进程是父进程的一个`复制品`，而execve函数在`当前进程`的上下文中加载并运行新程序，它会`覆盖`当前进程的地址空间，但并`没有`创建一个新进程

## 信号

信号允许内核或进程`中断`其他进程

一个信号就是一条消息，它`通知进程`系统中发生了一个某种类型的事件

传送一个信号有两个步骤：发送信号和接收信号

### 发送信号

`内核`通过更新目的进程上下文中的`某个状态`，发送一个信号给目的进程

一个进程可以发送信号给它自己

发送一个信号可能有两种原因：

- 1.内核检测到一个`系统事件`，如零除错误或子进程终止

- 2.一个进程调用了`kill函数`

向进程发送信号的机制都是基于`进程组`这个概念的

#### 进程组

每个进程都只属于一个`进程组`，它由一个正整数`进程组ID`来标识

子进程默认与父进程同组，进程可以使用setpgid函数来改变自己或其它进程的进程组

如果kill函数的参数pid为0，则会向调用进程`所在进程组中的每个进程`（包括调用进程自己）发送信号

#### 作业 job

Unix shell使用`作业（job）`来表示对一条命令行求值而创建的进程，任何时刻至多只有一个前台作业和多个后台作业

命令：

```
ls | sort
```

会创建一个由`两个进程`组成的前台作业，它们通过Unix管道连接起来，一个进程运行ls程序，一个运行sort程序

shell为每个作业创建一个`独立的进程组`

在键盘上输入`Ctrl+c`会发送SIGINT信号到前台进程组的每个进程，这将终止前台作业


### 接收信号

目的进程被内核`强迫`以某种方式对信号的发送作出反应时，它就`接收`了这个信号

进程可以`忽略`这个信号，终止或者通过执行信号处理程序`捕获`这个信号


每种类型最多只能有`一个未处理的信号`，且如果存在一个未处理的信号，说明至少有一个信号`到达`了

# 虚拟内存

为了更有效的管理内存并减少出错，现代系统提供了一种对主存的抽象概念，称为虚拟内存

虚拟内存提供了三个重要的能力：

- 1.将主存看成是磁盘的高速缓存，在主存中只保存活动区域，并根据需要在主存和磁盘之间传送数据

- 2.为每个进程提供了`一致`的地址空间

- 3.`保护`了每个进程的地址空间不被其它进程破坏

## 物理和虚拟寻址

- 物理寻址：CPU直接向主存发送一个物理地址，获取其中的内容

- 虚拟寻址：CPU通过生成一个虚拟地址来访问主存，虚拟地址在被送到主存之前先`转换`成适当的物理地址，这个过程称为`地址翻译`

## 地址空间

每个数据对象可以有多个`独立的地址`，每个地址都选自不同的`地址空间`，这是虚拟内存的基本思想

主存中的每个字节都有一个选自虚拟空间的`虚拟地址`和选自物理地址空间的`物理地址`

## 虚拟内存作为缓存的工具

虚拟内存被组织成一个由存放在`磁盘`上的N个连续字节组成的数组，磁盘上数组的内容被缓存在主存中

VM系统将虚拟内存分割成`虚拟页`，在任意时刻，有三种虚拟页：

- 1.未分配的，还未创建的页，不占用磁盘空间

- 2.缓存的，已经缓存在物理内存中的已分配页

- 3.为缓存的，未缓存在物理内存中的已分配页

通过`页表`将虚拟页映射到物理页，而页表是储存在`物理内存`中的

## 虚拟内存作为内存管理的工具

操作系统为每个进程提供了独立的`页表`，也就是一个独立的`虚拟地址空间`

虚拟地址能够实现以下内存管理优化：

- 1.简化链接，独立的地址空间允许每个进程的内存映像使用`相同的基本格式`，这可以简化链接器的设计和实现

- 2.简化加载，加载器为代码和数据段分配虚拟页，而`不需要`从磁盘到内存`实际复制`任何数据，虚拟内存系统会在需要时自动调入数据页

- 3.简化共享，每个进程拥有自己私有的信息，但也有一些信息是可以共享的，操作系统可以将共享的虚拟页面映射到`同的物理页面`

- 4.简化内存分配，用户进程需要分配额外的内存时，操作系统分配一个`连续的虚拟内存页面`，但可以映射到`非连续的物理内存页面`

## 虚拟内存作为内存保护的工具

可以通过在页表中增加一些`许可位`来限制某些进程可执行的操作

## 地址翻译

地址翻译是一个N元素的虚拟地址空间（VAS）和一个M元素的物理地址空间（PAS）中元素之间的映射

当页面命中时，执行顺序为：

- 1.`处理器`生成一个虚拟地址，传送给`MMU`（内存管理单元）

- 2.`MMU`生成PTE（页表条目）地址，并从`高速缓存或主存中`请求得到它

- 3.高速缓存或主存向MMU返回PTE

- 4.MMU根据PTE构造物理地址，并传送给高速缓存或主存

- 5.高速缓存或主存将物理地址中的数据传送给处理器

当页面不命中时，前三步完全相同

- 4.PTE中的有效位为0，MMU触发一个异常，将控制传递到系统内核中的缺页异常处理程序

- 5.缺页处理程序确定物理内存中的`牺牲页`，如果这个页面被修改了，则将它换出到`磁盘`

- 6.缺页处理程序调入新的页面，并更新内存中的PTE

- 7.缺页处理程序返回到原来的进程，`重新执行`导致缺页异常的指令，此时可以命中

通过在MMU中增加一个PTE的缓存：`翻译后备缓冲器（Translation Lookaside Buffer TLB）`，可以加速地址翻译

通过将页表分级，每一指向不同大小的`数据片`，可以节省内存


## 内存映射

Linux通过将一个虚拟内存`区域`与一个`磁盘`上的对象关联起来，以初始化这个虚拟内存区域的内容，这个过程称为`内存映射`

虚拟内存区域可以映射到两种类型的对象：

- 1.普通文件，如可执行目标文件

- 2.匿名文件，匿名文件是由内核创建的，包含的全是`二进制0`，匿名文件是驻留在内存中的，并`没有`对应实际的磁盘文件

一旦一个虚拟页面被初始化，它就在一个由内核维护的专门的`交换文件（swap file）`（或交换空间）中换来换去，交换空间限制着当前运行的进程能够分配的`虚拟页面总数`

### 共享对象

一个对象可以被映射到虚拟内存的一个区域，要么作为共享对象，要么作为私有对象

映射共享对象的区域中所做的任何写操作，对于将这个共享对象映射到它们虚拟内存的其他进程而言也是`可见的`

而映射私有对象的区域的改变，对于其他进程是不可见的，并且进程对这个区域所做的任何写操作都`不会反映在磁盘上的对象中`

对于共享对象，即使对象被映射到了多个共享区域，物理内存中也只需要存放共享对象的`一个副本`

对于私有对象，它以一种叫做`写时复制`的技术被映射到虚拟内存中，最开始物理内存中也只有一个私有对象的副本，对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为`只读`，区域结构被标记为`私有的写时复制`，当有进程`试图写`私有区域内的某个页面时，将触发一个保护故障

写私有的写时复制区域引起的故障处理程序会在物理内存中创建页面的一个`新副本`，并更新页表条目指向这个新副本，然后恢复页面的`可写权限`，在新的页面上写操作可以正常执行

## 动态内存分配

动态内存分配器维护一个`进程`的虚拟内存区域，称为`堆`

分配器将堆视为一组不同大小的`块`的集合，块可以是`已分配的`或`空闲的`

- 显式分配器：malloc

- 隐式分配器：垃圾收集器，自动释放`未使用`的`已分配`的块

### 碎片

有未使用的内存但不能满足分配请求，碎片会造成堆利用率降低

- 内部碎片，一个已分配块比它的有效载荷大，比如为了2字对齐，将5字节的块填充至6字节

- 外部碎片，空闲内存合计起来足够满足分配请求，但是没有`单独`的空闲块足够大来处理这个请求

分配器要尽量维持`少量的大空闲块`

### 隐式空闲链表

分配器要频繁地处理块的分配与释放操作，需要记录空闲块，选择合适的空闲块来放置新分配的块，并在新放置块之后，处理空闲块中的剩余部分，还要合并被释放的块，从而在吞吐率和利用率之间把握平衡

这些操作可以通过一种叫做隐式空闲链表的简单`空闲块`来实现

块也有`头部`，存储块的`大小`以及`是否已分配`

将堆组织为一个连续的已分配块和空闲块的序列，这种结构称为`隐式空闲链表`，分配器通过`遍历堆中所有的块`来得到空闲块的集合

放置策略：首次适配、下一次适配和最佳适配

合并策略：立即合并与推迟合并 （边界标记，脚部是头部的一个副本）

### 显式空闲链表

对于空闲块，在隐式空闲链表的有效载荷的前面添加一个pred前驱指针和succ后继指针

### 分离的空闲链表

使用单向空闲链表因为需要进行遍历，所以在分配时需要与空闲块数量呈线性关系的时间

为减少分配时间，可以采用`分离存储`，就是维护多个空闲链表，每个链表中的块有`大致相同的大小`，通常将所有可能的块的大小分成等价类，称为`大小类`

当分配器需要一个大小为n的块时，根据大小类搜索相应的链表

## 垃圾收集器

垃圾收集器是一种`动态内存分配器`，它自动释放程序不再需要的已分配块

垃圾收集器将内存视为一张`有向可达图`，包括一组`根节点`和一组`堆节点`，每个堆节点对应堆中的一个`已分配块`，根节点对应于不包含在堆中的位置

在任何时刻，不可达节点对应于`垃圾`，垃圾收集器`定期`地释放它们并将它们返回给空闲链表

垃圾收集器代替应用来调用free

### Mark&Sweep垃圾收集器

`Mark&Sweep垃圾收集器`由标记和清除阶段组成，标记阶段标记出所有可达的和已分配的后继，清除阶段释放未被标记的已分配块

# 系统级I/O

`输入`是从I/O设备复制数据到主存，`输出`是从主存复制数据到I/O设备

内核提供系统级`Unix I/O函数`，在语言运行时，系统提供执行I/O的较`高级别工具`

所有的I/O设备都被模型化为`文件`，输入和输出则被当作相应文件的`读和写`来执行，这种方式称为Unix I/O，能够使得所有的输入和输出都能以统一且一致的方式来执行：

- 打开文件，应用程序通过要求内核打开相应的文件，来宣告它想要访问一个I/O设备，内核返回一个小的`非负整数`，叫做`描述符`，内核记录有关这个打开文件的所有信息，应用程序只需要记住这个描述符

- Linux shell创建的每个进程开始时都有三个打开的文件：`标准输入（0）`、`标准输出（1）`和`标准错误（2）`

- 改变当前的文件位置，内核保持一个文件位置k，表示从文件开头起始的`字节偏移量`，初始为0

- 读写文件，读操作就是从文件复制n>0个字节到内存，从当前文件位置k开始，如果一个m字节的文件，`k>=m`时执行读操作会触发一个称为`end-of-file(EOF)`的条件

- 关闭文件，应用完成了对文件的访问之后，就通知内核关闭这个文件，内核将释放文件打开时创建的数据结构，然后将`描述符恢复`到可用的描述符池中，当进程终止时，内核会关闭所有打开的文件

## 文件

每个Linux文件都有一个类型

- 普通文件，包含任意数据，包括`文本文件`和`二进制文件`，文本文件是`只含有`ASCII或Unicode字符的普通文件，二进制文件是`所有其他的文件`，对内核而言，二者没有区别

- 目录是包含一组链接的文件，每个链接都将一个文件名映射到另一个文件，每个目录至少包含两个文件，`.`是到该目录自身的链接，`..`是到父目录的链接

- 套接字是用来与另一个进程进行跨网络通信的文件

## 打开和关闭文件

进程通过调用`open`函数来打开一个已存在文件或创建一个新文件，通过调用`read`和`write`函数来执行输入和输出

有时read和write传送的字节比应用程序要求的少，称为`不足值`，但不表示有错误

- 使用`RIO（Robust I/O）包`能够自动处理不足值

RIO提供了两类不同的函数：无缓冲的输入输出函数和带缓冲的输入函数

- 应用程序通过调用stat和fstat函数来检索关于文件的信息（元数据），包括文件大小，类型，权限等等

- 目录内容通过调用readdir函数来读取，它以路径名为参数，返回指向`目录流`的指针，目录流是堆条目有序列表的抽象

## 共享文件

Linux内核用三个相关的数据结构来表示打开的文件

- 1.描述符表，表项有进程打开的文件描述符来索引，每个打开的描述符表项指向`文件表`的一个表项

- 2.文件表，打开文件的集合，所有的进程`共享`这张表，表项包括当前的`文件位置`，`引用计数`以及一个指向`v-node表`对应表项的指针，关闭描述符会减少相应的引用计数，引用计数为`0`时这个文件表表项将被删除

- 3.v-node表，同样被所有进程`共享`，表项包含文件状态信息

多个描述符可以通过不同的文件表项引用同一个文件，因为每个描述符都有它自己的`文件位置`，所以对不同描述符的读操作可以从文件的不同位置获取数据

在调用fork后，子进程获得父进程的`描述符表的副本`，所以它们共享相同的文件表


## I/O重定向

```
ls > foo.txt
```

中的`>`就是一个Linux shell提供的I/O重定向操作，它使磁盘文件和标准输入输出联系起来

I/O重定向可以通过调用`dup2(int oldfd, int newfd)`函数来实现，它复制旧描述符表项oldfd到新描述符表项newfd，并覆盖newfd表项以前的内容

## 标准I/O

C语言定义了一组高级输入输出函数，称为`标准I/O库`，它将一个打开的文件模型化为一个`流`，可以视为一个指向FILE类型的`指针`

类型为FILE的流是对`文件描述符`和`流缓冲区`的抽象

- 在网络应用中应该使用RIO而不是标准I/O，因为对于同一个流输入函数和输出函数之间`不能相邻`，必须要先清空缓冲区或充值文件当前位置，但是套接字不能够调用这些函数

# 网络编程

客户端-服务器模型中，客户端和服务器都是`进程`，而不是主机

## 网络

对于主机而言，网络只是一种`I/O设备`，是数据源和数据接收方

网络适配器插到I/O总线扩展槽上，网络通过I/O和内存总线与内存交换数据

- 在应用层和传输层之间是套接字接口，通过`系统调用`从客户端进程的虚拟地址空间复制数据到内核缓冲区中

- 在网络层和链路层之间，通过`中断`来调用硬件网络适配器

网络传输是`大端`字节顺序（高位存放起始地址）

- 每台因特网主机都有本地定义的域名localhost，它映射为`回送地址127.0.0.1`

### 因特网连接

因特网连接的端点是`套接字`，套接字地址是`IP地址：端口`

## 套接字接口

套接字接口是一组`函数`，它们与Unix I/O函数结合起来创建网络应用

对于Linux程序来说，套接字就是一个拥有响应描述符的`打开文件`

- socket函数用来在客户端和服务器创建`套接字描述符`

- connect函数倍客户端用来建立和服务器的连接，得到的连接是由`套接字对`刻画的

- bind函数用来在服务器端告诉内核将addr中的`服务器套接字地址`和`套接字描述符`连接起来

- listen函数用于告诉内核，描述符是被服务器使用的，因为内核会默认socket函数创建的描述符对应于`主动套接字`（即客户端），listen将主动套接字转换为`监听套接字`

- accept函数被服务器调用来`等待`来自客户端的连接请求，它将返回一个`已连接描述符`

    - 监听描述符和已连接描述符的区别：监听描述符是作为客户端连接请求的一个端点，只被创建`一次`；已连接描述符是已经建立的连接的一个端点，服务器`每次`接收连接请求时都会创建一次，它只存在于服务器为一个客户端服务的过程中
    
## Web服务器

Web服务和其它网络服务主要的区别是Web服务可以使用HTML（Hypertext Markup Language，超文本标记语言）来编写

对于Web客户端和服务器而言，内容是与一个`MIME`（Multiplurpose Internet Mail Extensions，多用途的网际邮件扩充协议）类型相关的`字节序列`

- 静态内容：磁盘文件

- 动态内容：运行时可执行文件的`输出`

### 服务动态内容

动态内容需要遵守`CGI`(Common Gateway Interface，通用网关接口)标准

- 1.动态内容请求的参数在URI中传递，如

```
GET /cgi-bin/adder?15000&213 HTTP/1.1
```

`?`分割文件名和参数，每个参数用`&`隔开

- 2.当服务器接收到这样的请求后，它调用fork来创建一个`子进程`，子进程将CGI环境变量设置为`15000&213`，并调用execve在子进程的上下文中执行`/cgi-bin/adder`程序

- 3.CGI程序会将动态内容发送到`标准输出`，所以在子进程运行程序之前，首先使用Linux dup2函数将标准输出重定向到和客户端相关联的`已连接描述符`（accept）

*P671 TINY服务器*

# 并发

逻辑控制流在时间上重叠，则它们是并发的

操作系统提供了三种构造并发程序的办法：

- 1.进程，每个逻辑控制流都是一个进程，必须使用显示的`进程间通信机制`(interprocess communication, IPC)来和其它流通信

- 2.I/O多路复用，进程调动`自己`的逻辑流，逻辑流被模型化为状态机，数据到达文件描述符后，主程序显式地从一个状态转换到另一个状态，程序在一个单独的进程中，所有的流共享`同一个地址空间`

- 3.线程，可以看作上面两种方式的混合，像进程流一样由内核进行调度，像I/O多路复用流一样共享同一个虚拟地址空间

## 基于进程的并发

比如Web服务器中，父进程接收客户端的连接请求，创建一个新的子进程来为每个客户端提供服务（创建子进程后，父进程必须关闭相应的资源以避免内存泄漏）

在父子进程之间，进程共享`文件表`，但不共享`用户地址空间`

进程控制和IPC的开销很高，所以进程的并发比较慢

## 基于I/O多路复用的并发

基本思路是使用select函数，要求内核挂起`进程`，只有在`一个或多个I/O事件`发生之后，才将控制返回给应用程序

select函数处理`描述符集合`，它会一直阻塞直到集合中有一个描述符准备好

### 基于I/O多路复用的并发事件驱动服务器

在`事件驱动`程序中，某些事件会导致流向前推进，一般的思路是将逻辑流模型转化为状态机

状态机是一组`状态`、`输入事件`和`转移`

转移是将一个输入事件，输入状态映射到输出状态

- 相比于基于进程的并发，基于I/O多路复用的并发`共享数据容易`（单一进程上下文），`性能更好`（不需要进程上下文切换来调动新的流），但是编码复杂且不能充分利用多核处理器


## 基于线程的并发

线程是在进程上下文中的逻辑流，由`内核自动调度`，每个线程有自己的线程上下文，包括唯一的整数线程ID（Threading ID, TID）栈、栈指针、程序计数器、通用目的寄存器和条件码，同一个进程里的线程`共享`该进程的整个虚拟地址空间

### 线程执行模型

每个进程开始时都是单一线程，称为`主线程`，在某一时刻，主线程创建`对等线程`，自此刻开始，两个线程并发运行

线程不像进程那样按照父子结构，而是组成一个`对等线程池`，一个线程可以杀死任何它的对等线程，或等待它的任意对等线程终止

### 线程相关操作

C语言中使用`Posix线程`（Pthreads）标准接口来处理线程

- 创建线程：线程通过调用pthread_create函数来创建其他线程

- 终止线程：线程终止可以有以下几种方式：
    - 1.顶层的线程例程返回时，线程`隐式`地终止
    - 2.调用pthread_exit函数（自己调用自己），线程`显式`地终止，如果主线程调用了pthread_exit，则会等待所有其它对等线程中使，再终止主线程和`整个进程`
    - 3.某个线程调用Linux的exit函数，这将`终止进程`以及所有与进程相关的线程
    - 4.另一个对等线程以`当前线程ID`作为参数调用pthread_cancel函数来终止`当前线程`

- 分离线程

线程由两种状态：`可结合的`或是`分离的`，可结合的线程能够被其他线程收回和杀死，在被回收之前，它的内存资源`不释放`；分离的线程不能被其他线程回收或杀死，内存资源在终止时由`系统自动释放`

## 多线程中的共享变量

一个变量是`共享`的，当且仅当多个线程引用这个变量的某个实例

每个线程有独立的线程上下文，包括线程ID、栈、栈指针、程序计数器、条件码和通用目的寄存器，每个线程与其他线程共享`进程上下文`的其他部分，包括整个`用户虚拟地址空间`

对于全局变量和本地静态变量（static），在运行时虚拟内存的读/写区域只会包含`一个实例`，所有的线程共用它；对于本地自动变量（没有static），每个线程的栈都有它`自己的实例`

## 使用信号量同步线程

借助`进度图`分析指令顺序的概念

要确保每个线程在执行进度图中临界区中的指令时，对共享变量的访问是互斥的

### 信号量

信号量s是一个非负整数，是全局变量，只能通过P和V两种特殊的操作来处理

- P(s)：
    - 如果s非0，P将s减1，并立即返回
    - 如果s为0，就`挂起`这个线程，直到s变为非0，另一个V操作会重启这个线程，重启后P将s减1，将控制返回给调用者

- V(s):将s加1，如果有线程阻塞在P等待s变成非0，V将重启这些线程中的`一个`（随机），然后将s减1，完成它的P操作

P和V操作都是`不可分割`的，过程中不能被中断

### 使用信号量实现互斥

基本思想是将每个共享变量与一个信号量s（初始为1）联系起来，然后用P和V操作将相应的临界区包围起来

这种信号量称为`二元信号量`，它的值总是0或1，以提供互斥为目的的二元信号量称为`互斥锁`，执行P操作称为对互斥锁`加锁`，V操作称为`解锁`，一个加了锁但还没解锁的线程称为`占用`这个互斥锁

在进度图中s小于0的区域是实际上不能够到达的区域，称为禁止区

### 利用信号量来调度共享资源

在共享资源访问的场景中，一个线程用信号量来通知另一个线程，某个条件`已经为真`了

#### 生产者-消费者问题

生产者和消费者共享一个有n个槽的有限缓冲区，生产者线程反复生成新的`项目`，并插入到缓冲区中，消费者线程不断地从缓冲区中取出这些项目

在这种模型中，除了要保证对缓冲区的访问是互斥的之外，还需要`调度`对缓冲区的访问，比如一个缓冲区是满的，那么生产者线程必须等待

#### 读者-写者问题

写者必须拥有对对象的`独占`的访问，而读者可以和其它`无限多读者`共享对象

## 使用线程提高并行性

并行程序是一个运行在`多个处理器`上的并发程序

随着线程的增加，程序运行可能会变慢，这是因为线程间的`同步开销很大`，在应用中应该尽可能多的用有用及计算来弥补这个开销（或者可以在每个线程的私有变量中进行计算，省去了每一次同步的开销），并行程序通常写为每个核上只运行一个线程

## 一些并发问题

### 线程安全

当且仅当一个函数被多个并发线程反复的调用时，总能产生正确的结果，成这个函数是`线程安全的`，否则是`线程不安全的`

有四个线程不安全函数类：

- 1.不保护共享变量的函数，可以通过加锁来将其变成线程安全

- 2.保持跨越多个调用的状态的函数，比如修改全局变量，修改方法只能是让函数不再使用全局变量，而是依靠调用者在参数中传递状态信息

- 3.返回指向静态变量的指针的函数，可以通过修改代码，使得调用者传递`地址`；或者使用`加锁-复制`技术：首先对互斥锁加锁，然后调用线程不安全函数，将函数返回的结果复制到一个私有的内存位置，然后对互斥锁解锁

- 4.调用线程不安全函数的函数

### 可重入性

可重入函数在被多个线程调用时，`不会引用任何共享数据`

可重入函数是线程安全函数的一个`真子集`

可重入性除了与函数本身相关，也与调用者传入的参数相关（比如调用者传入指向非共享数据的指针，它就是可重入的）

### 使用已存在的库函数

Linux系统提供大多数线程不安全函数的可重入版本，它们以`_r`为后缀

### 竞争

当程序的正确性依赖于一个线程要在另一个线程到达y点之前到达它的控制流的x点，就会发生竞争

发生竞争通常是因为违反了一条准则：多线程的程序必须对`任何可行的轨迹线`都正确工作

### 死锁

死锁值得是线程被阻塞并等待一个永远也不会为真的条件

在进度图中，两个信号量禁止区重叠部分的下方就是`死锁区`，可以认为死锁是因为每个线程都在等待其他线程执行一个不可能发生的V操作

可以使用`互斥锁加锁顺序规则`来避免死锁：

- 如果每个线程都以一种顺序获得互斥锁并以`相反顺序释放`，则这个程序是无死锁的
