# 基础知识

TCP(Transmission Control Protocal) 传输控制协议

它提供了任意长度消息的可靠传输，定义了所有类型数据在网络中的一种健壮传递机制

IP(Internet Protocal) 网际协议

它管理从发送方到接收方的网络传输的路由，并处理于网络和计算机寻址相关的问题


IPV4 32位

IPV6 可以支持128位，目前运营商提供的一般为64位

## ISO/OSI 网络参考模型

ISO/OSI全名 International Organization for Standardization Open Systems Interconnection (国际标准化组织开放系统互连)

前四层为主机层，后三层为介质层

|  数据   | 分层  |
|  :----:  | :----:  |
| 数据  | 应用层 |
| 数据  | 表示层 |
| 数据  | 会话层 |
| 数据段  | 传输层 |
| 分组  | 网络层 |
| 数据帧  | 数据链路层 |
| 比特位 | 物理层 |

一般来说，各层为上一层提供服务，并向下一层交付数据或从下一层接收数据

PDU（Protocal Data Unit，协议数据单元）是在各层传输的数据包

### 1.物理层

物理传输介质（电缆或无线传输介质）

任务是建立、维持和断开网络连接

物理层管理`网络介质`到`协议栈`的通信，发送时将出栈数据转换为网络信号，接收时相反

物理层的数据（PDU）由串行信号组成，对应数据链路层里数据帧的比特位

### 2.数据链路层

任务是确保在`发送方`实现物理层数据的可靠传输，在`接收方`

通过唯一标识每一个网卡的专用地址，识别本地介质上的每个设备

管理网卡之间的`点对点`通信

`介质流控制` 数据链路层能够控制从发送方到接收方数据传输的节奏

### 3.网络层

主要功能是对Internet上的每一个主机提供一个`全球唯一的地址`，并提供主机之间的通信路径

包含DNS（Domain Name System，域名系统）

- 分组交换
- 阻塞控制


### 4.传输层

确保发送方到接收方PUD可靠的端到端传输

在这一层需要进行数据`校验`

数据的`分段`与`重组`：在发送方分段，接收方重组

传输层的PDU称为`数据段`

### 5.会话层

会话层是在发送方和接收方之间进行通信时创建、维持、之后终止或断开连接的地方

通过`检查点`机制来维持可靠会话

### 6.表示层

表示层管理从`网络通用的数据`到`特定机器（或应用程序）`上的数据变换，以及反向变换

`重定向器`（或网络外壳）：将本地资源请求与网络资源请求区分开

### 7.应用层

应用程序用于请求网络程序的`接口`，而不是应用程序本身

应用层定义了应用程序能够从网络上请求的几种类型的`服务`，并且规定了`数据所采用的格式`

## TCP/IP网络模型

是与OSI参考模型对应的另一种模型，它分为4层

### 1.网络访问层

对应物理层+数据链路层

PPP(Point to Point Protocal)点对点协议，用于在两个网络设备之间建立直接的连接

网络访问层（OSI第二层）还包括一些不属于TCP/IP协议族的协议：

- HDLC（High-level Data Link Control) 高速数据链路控制协议
- 帧中继（Frame Raley）
- ATM （Asynchronous Transfer Mode） 异步传输模式


### 2.互联网层

对应网络层

主要有三个基本功能：数据分片、寻址、路由

互联网层的主要协议：

- IP （Internet Protocal） 网际协议：负责把数据包从发送方路由到接收方
- ICMP （Internet Control Message Protocal） Internet控制消息协议
- ARP （Address Resolution Protocal） 地址解析协议：IP地址--MAC地址
- RARP （Reverse Address Resolution Protocal） 反向地址解析协议：MAC地址--IP地址
- BOOTP （Bootstrap Protocal） 自举协议
- RIP （Routing Information Protocal） 路由信息协议：定义了`跳数`（发送方到接收方经过的路由器个数）
- OSFP （Open Shortest Path First） 开放式最短路径优先协议
- BGP （Border Gateway Protocal） 边界网关协议

### 3.传输层

对应传输层

提供了一台主机到另一台主机的数据移动

基本功能包括发送方到接收方的`可靠数据传输`、出站前必要的`消息分段`以及在把数据交给应用层之前`重组分段`

传输层的协议有两个：

- TCP （Transmission Control Protocal） 传输控制协议

`面向连接的`协议，发送数据之前在发送方和接收方之间协商并`维持连接`

- UDP （User Datagram Protocal） 用户数据报协议

`无连接的`协议，以一种“尽最大努力交付”的方式简单地发送数据，在接收方没有任何后续的检验

### 4.应用层

对应会话层+表示层+应用层

协议栈与主机上的应用程序进行交互的地方

TCP/IP服务的运行依赖于两个要素：`守护进程`和`端口地址`


## 套接字

特定`IP地址`+`动态分配端口号`的组合称为套接字地址（Socket Address），简称套接字（Socket）

动态分配端口号指的是`1024~65536`之间的，在需要时为发送方和接收方之间提供有限数据交换的`临时`连接时用到的端口号


# 《计算机网络：自顶向下方法》

## 网络核心

网络核心指的是因特网端系统的分组交换机和链路构成的网状网络

### 分组交换

为了从源端向目的端发送一个报文，源将长报文划分为较小的数据块，称为`分组`

每个分组通过通信链路和`分组交换机`传送。分组交换机主要有两类：`路由器`和`链路层交换机`

#### 1.存储转发传输

存储转发传输指的是交换机必须等待整个分组`全接收完`才能开始发送

#### 2.排队时延和分组丢失

类似于买东西排队，当数据量大时，数据需要在分组交换机的`输出队列`中进行等待

#### 3.转发表和路由选择协议

类比于问路，数据想要去往目的地，数据包的首部包含了目的地的`IP地址`，通过路由器进行“问路”，但中间的路由器并不知道如何去往最终的目的地，它只是知道经由附近的哪个路由器能够
最终走到目的地（`路由表`），所以它将数据转发给相邻的路由器，由此一步步数据最终能够被发送到目的地


### 电路交换

与分组交换不同，电路交换会为即将到来的数据传输`预留资源`，当数据发送时，不需要等待就可以直接传输

这样带来的弊端就是因为要为其他的数据传输预留资源，所以电路交换的每一个传输都只能使用`一部分的链路传输资源`


### 分组交换网中的时延

有以下几种时延：节点处理实验，排队时延，传输时延和传播时延，加起来是节点总时延

#### 1.处理时延

包括检查分组首部和决定该分组导向何处等

#### 2.排队时延

如果当前传输队列有其他分组正在传输，当前分组就需要等待

#### 3.传输时延

指的是将所有比特推向链路所需要的时间（这部分在节点内部完成）

#### 4.传播时延

从起点到终点需要的时间（在路上）

### 分组交换网中的丢包

丢包与`排队时延`有关，需要先说明一个概念：`流量强度`

- 流量强度

如果a表示分组到达队列的平均速率，R表示传输速率，L表示该分组由L个比特组成

则流量强度等于`La/R`

假如`La/R>1`，则比特到达队列的平均速度将超过传输出去的速度，丢列趋于无限增加，所以设计系统时`流量强度不能大于1`

- 丢包

当流量强度小于1的时候，随着流量强度接近1，排队时延并不趋向无穷大，相反，到达的分组将发现一个满的队列，由于没有地方存放这个分组，路由器将`丢弃`该分组，这就是丢包


### 吞吐量

若令Rs表示服务器与路由器之间的链路速率，Rc表示路由器与客户之间的的链路速率，这一两链路网络的吞吐量就是`min(Rs, Rc)`，就是所有速率中的最小值

而如果存在一条共享链路，其速率为R，假设允许同时存在10个传输，则吞吐量为`min(Rs, Rc, R/10)`，即共享链路的速率会被`平分`


## 因特网的5层协议栈（自顶向下）

### 1.应用层

包括网络应用程序以及它们对应的协议

HTTP、FTP、DNS等

数据为`报文`

### 2.传输层

在`应用程序端点`之间传输应用层报文

TCP、UDP

数据为`报文段`

### 3.网络层

负责将数据分组从一台主机移动到另一台主机

IP协议

数据为`数据报`

### 4.链路层

为了将分组从一个节点移动到下一个节点，网络层必须依靠链路层的服务

在每个节点，网络层将数据报`下传`给链路层，链路层沿着路径将数据报传递给下一个节点，在下一个节点，链路层将数据报`上传`给网络层

数据为`帧`

### 5.物理层

将数据帧中的一个个`比特`从一个节点移动到下一个节点

数据是`比特`

### 封装

在发送端，数据自上而下层层封装，每一层都加上该层特有的信息

在接收端，数据自下而上层层解封，每一层都去掉关于该层的信息


# 应用层

## 应用层协议原理

### 体系结构

应用层主要有两中应用程序体系结构：`客户-服务器体系结构`和`对等（P2P Peer to Peer）体系结构`

- 客户-服务器体系结构

客户-服务器体系结构中有一个`总是打开的主机`称为服务器，允许许多客户主机的请求

而且服务器具有`固定的、周知的`地址

- P2P体系结构

P2P体系结构对位于数据中心的专用服务器有最小的（或没有）依赖，应用程序在间断连接的`主机对`之间`直接通信`，这些主机称为`对等方`

P2P体系具有`自扩展性`

### 进程通信

进行端与端通信的是`进程`，两个不同端系统上的进程，通过网络交换`报文`而相互通信

在一对进程之间的通信中，将`发起通信`的进程标识为客户，在会话开始时`等待联系`的进程是服务器

进程通过称为`套接字`的软件接口向网络发送报文和从网络接收报文，套接字也称为`应用程序编程接口(Application Programming Interface API)`

套接字是同一台主机内`应用层`与`传输层`之间的接口

在通信中`主机`由`IP地址`标识，`在目的主机中指定接收的进程`由`端口号`标识

### 应用程序对传输层的要求

应用程序对传输层的要求大体有四个方面：可靠数据传输、吞吐量、定时和安全性

### 因特网提供的运输层服务

- TCP: 面向连接、可靠的数据传输

由于TCP不提供加密机制，所以研制出了`SSL（Secure Sockets Layer）安全套接字层`，它能提供`进程到进程`的安全性服务，SSL是一种`对TCP的加强`，这种强化是在`应用层`实现的

- UDP: 无连接、不可靠的数据传输、没有阻塞控制机制

## Web 与 HTTP

`Web`页面是由对象组成的，一个对象可以是一个HTML文件、一个图片，Java小程序等

多数页面由一个HTML基本文件以及几个引用对象（比如几张图片）组成，HTML基本文件通过`对象的URL地址`引用页面中的其他对象，URL地址由`存放对象的服务器主机名`和`对象的路径名`两部分组成

`HTTP`（HyperText Transfer Protocal 超文本传输协议）是Web的核心，它使用`TCP`作为支撑传输协议，且HTTP服务器不会保存客户状态的信息，所以说HTTP是一个`无状态协议`

### 持续连接与非持续连接

- 持续连接：所有的请求及其响应都由相同的TCP连接发送

- 非持续链接：每个请求/响应对是经由一个单独的TCP连接发送

HTTP默认使用`持续链接`，但也可以配置成非持续连接

非持续连接需要为`每一个对象`的请求建立和维护一个全新的TCP连接，这将给服务器带来严重的负担

而持续连接中，对所有对象的请求可以一个接一个的发出，而`不必等待对未决请求的回答`，当一条连接经过`一定时间间隔`仍未被使用，HTTP服务器将关闭这个连接

- RTT（Round-Trip Time 往返时间）指的是一个`短分组`从客户到服务器再返回客户所需的时间


### HTTP报文格式

HTTP报文由请求报文和响应报文两种

#### 请求报文

下面给出一个典型的HTTP请求报文格式

```
GET /somedir/page.html HTTP/1.1
Host: www.someschool.edu
Connection: close
User-agent: Mozilla/5.0
Accept-language: fr
```

HTTP请求报文的第一行叫做`请求行`，后继的行叫做`首部行`

请求行有三个字段：`方法字段`、`URL字段`和`HTTP版本字段`

- 方法字段，包括GET, POST, HEAD, PUT和DELETE
- URL字段，它带有请求对象的标识
- HTTP版本字段，表示了使用的协议版本

在首部行中

- `HOST: www.someschool.edu` 指明了对象所在的主机，该信息是Web高速缓存所需要的
- `Connectioin: close` 告诉服务器使用非持续连接
- `User-agent: Mozilla/5.0` 指明用户代理，即发送请求的浏览器版本
- `Accept-language: fr` 表示想要得到该对象的法语版本

在HTTP报文中，首部行之后还有一个`实体体`，使用GET方法时，实体体为空，当使用POST方法时使用实体体

当然想要提交表单时也可以通过在URL中带上参数来实现

其他的一些方法字段：

- HEAD：与GET类似，但服务器接收到HEAD请求时只会返回HTTP报文，`不会返回对象`
- PUT：允许用户上传对象到服务器的指定位置
- DELETE：允许用户删除服务器上的指定对象

#### 响应报文

下面是一个典型的响应报文：

```
HTTP/1.1 200 OK
Connection: close
Date: Tue, 18 Aug 2015 15:44:04 GMT
Server: Apache/2.2.3 (CentOS)
Last_Modified: Tue, 18 Aug 2015 15:11:03 GMT
Content-Length: 6821
Content-Type: text/html

(data data data ...)
```

它有三个部分：一个初始`状态行`、6个`首部行`、以及`实体体`

状态行有三个部分：`协议版本`、`状态码`和`状态信息`

在首部行中：

- `Connection: close` 告诉用户，发送完报文后将关闭TCP连接
- `Date` 指示服务器产生并发送该响应报文的时间
- `Server` 指示服务器版本（与User-agent类似）
- `Last-Modified` 表示对象创建或者最后修改的时间
- `Content-Length` 指示被发送对象的字节数
- `Content-Type` 指示被发送对象的格式

常见状态码及相关短语

- 200 OK：请求成功，信息在返回的响应报文中
- 301 Moved Permanently：所请求的对象已经被永久转移了，新的URL在响应报文的`Location`首部行中，用户软件可以`自动获取`新的URL
- 400 Bad Request：指示该请求不能被服务器理解
- 404 Not Found：请求的文档不在服务器上
- 505 HTTP Version Not Supported：服务器不支持该请求报文的HTTP版本

### cookie

cookie可以在无状态的HTTP上建立一个`用户会话层`

在一次会话中设置cookie的流程为：

- 1.用户A首次访问服务器，服务器为A生成一个`唯一识别码`，并以此为索引在后端数据库产生一个表项
- 2.服务器用一个包含`Set-cookie`首部的响应报文对用户A的浏览器返回响应，假设该唯一识别码为1234，则首部行为`Set-cookie: 1234`
- 3.浏览器接收到响应后，在它管理的cookie文件中添加一行内容，包含`服务器主机名`和`唯一识别码`
- 4.当A再次访问该服务器时，浏览器会自动抽取cookie文件中的内容，放在报文首部中，以`cookie: 1234`的格式发送，服务器就可以识别出是哪个用户

由上述过程，可以看出cookie技术有四个组件：

- 1.服务器响应报文中的Set-cookie首部行
- 2.请求报文中的cookie首部行
- 3.服务器上的后端数据库
- 4.用户端有一个cookie文件，并由浏览器管理

### Web缓存

Web缓存器也叫代理服务器，是能够`代表初始服务器`来满足HTTP请求的网络实体，它`既是客户又是服务器`

带有Web缓存器的会话过程如下：

- 1.浏览器向Web缓存器中的对象发起请求
- 2.Web缓存器检查本地是否保存了所请求对象的`副本`，如果有就向浏览器直接返回
- 3.如果没有副本，Web缓存器就向`初始服务器`请求该对象
- 4.Web缓存器请求到对象之后，在本地保存一个副本，再将该副本返回给浏览器

Web缓存器的优点：

- 1.能够大大减少对客户请求的响应时间
- 2.能够大大减少一个机构的接入链路到因特网的通信量
- 3.大大降低因特网上的通信流量，增加应用性能

### 条件GET方法

有时放在Web缓存器上的对象可能在初始服务器上进行了修改，这样由于缓存机制用户就不能够获取到最新版本的对象

为此，HTTP提供了一种机制，允许缓存器证实它的对象是最新的，这种机制就是`带条件的GET方法`

这种机制应用在`Web缓存器 -> 初始服务器`的会话中，方法仍然是GET，但要加上`If-modified=since`首部，比如

```
GET /fruit/kiwi.gif HTTP/1.1
Host: www.exotiquecuisine.com
If-modified-since: Wed, 9 Sep 2015 09:23:24
```

注意If-modified-since后面的时间其实是`上一次`Web缓存器从初始服务器上获得该对象的时间

如果初始服务器上的对象没有修改过，服务器将`只返回一个响应报文`，而不会返回对象内容


## 电子邮件SMTP

电子邮件系统包括`用户代理`、`邮件服务器`和`简单邮件传输协议（Simple Mail Transform Protocol SMTP）`

发送方和接收方各有一个邮件服务器

STMP一般不使用`中间服务器`

默认使用25号端口


## DNS 域名系统

DNS（Domain Name System）是将主机名转换到IP地址的目录服务，它有两部分

- 1.一个由`分层的DNS服务器`实现的`分布式数据库`
- 2.一个使得主机能够查询分布式数据库的`应用层协议`

DNS服务器通常是运行BIND的UNIX及其

DNS运行在`UDP`之上，使用53号端口

DNS通常是被其他应用层协议所使用的，比如当发送一个HTTP请求到www.someschool.edu时：

- 1.浏览器从URL中抽取出主机名。并将主机名传给`用户主机上DNS应用的客户端`
- 2.DNS客户向DNS服务器发送一个包含主机名的请求
- 3.DNS服务器返回一个包含对应主机名的IP地址的回答报文
- 4.本地DNS将IP地址发给浏览器，浏览器向该IP地址80端口的HTTP服务器发起一个TCP连接

DNS还有一些重要的功能：

- 1.主机别名：复杂的主机名（`规范主机名`）通常有一些易于记忆的主机别名，DNS也可以通过主机别名来获得IP地址
- 2.邮件服务器别名
- 3.负载分配：繁忙的站点可能运行在多个服务器上，它们通过一个`IP集合`与`规范主机名`绑定，在这种情况下，DNS可以在回答中`循环这些地址`，达到负载均衡的目的

### DNS的分布式、层次数据库

为了处理扩展性问题，DNS使用了大量的DNS服务器，它们以`层次`结构组织，大致来说供由3个层次：`根DNS服务器`、`顶级域（Top-Level Domain TLD）DNS服务器`和`权威DNS服务器`，其实还有一个`本地DNS服务器`（但它不算入DNS的层次结构中）

一个DNS服务的例子（书上P87）

假设本地主机名为`cse.nyu.edu`，本地DNS服务器为`dns.nyu.edu`，目标主机`gaia.cs.umass.edu`的权威DNS服务器为`dns.umass.edu`

- 1.主机首先向本地DNS服务器发送一个DNS查询报文，该报文包含目标主机名
- 2.本地DNS服务器将报文转发到根DNS服务器，根DNS服务器注意到`edu`后缀并向本地DNS服务器返回`负责edu的TLD的IP地址列表`
- 3.本地DNS服务器再次向这些`TLD之一`发送查询报文，TLD注意到`umass.edu`后缀，并向本地DNS服务器返回`权威DNS服务器的IP地址`，该权威DNS服务器就是`dns.umass.edu`
- 4.本地DNS服务器直接向权威DNS服务器查询报文，权威DNS服务器用目标主机`gaia.cs.umass.edu`的IP地址作为响应，查询成功

通常，向本地DNS服务器查询的方式是`递归查询`，其余是`迭代查询`

使用`DNS缓存`机制可以改善DNS服务的时延情况

### DNS记录和报文

所有的DNS服务器都储存了`资源记录（Recourse Record RR）`，RR提供了主机名到IP地址的映射

RR包含以下四个字段

```
(Name, Value, Type, TTL)
```

更多内容可以查看书P89

## P2P文件分发

在P2P文件分发中，每个`对等方`能够向任何其它对等方重新分发`它已经接收到的该文件的任何部分`

P2P是`自扩展的`

参与一个特定文件分发的所有对等方的集合称为一个`洪流（torrent）`，每个洪流中有一个`追踪器`，当一个新的对等方加入洪流时，追踪器随机的在洪流集合中
选取一个子集，并将它们的IP地址发给当前对等放方，当前对等方会与它们建立`并行的TCP连接`

`最稀缺优先`：当前对等方针对自己没有的块向邻居中找到最稀缺的块

`最高速率优先`：优先与最高速率的邻居连接

## 视频流和内容分发网

流视频的实现方式是使用`应用层协议`和以`高速缓存方式运行的服务器`

### 内容分发网

为了应对向全世界的用户分发巨量视频数据的挑战，几乎所有的主流公司都利用`内容分发网（Content Distribution Network CDN）`

CDN管理分布在`多个地理位置上的服务器`，在它的服务器中存储视频的副本（类似于因特网缓存）


### 套接字编程

具体程序请查看书P104

一个需要注意的点是TCP连接时服务器上有多个套接字，分为两种：

- 1.欢迎套接字

欢迎套接字是创建服务器应用时监听端口`等待用户连接`的那个套接字

- 2.连接套接字

连接套接字是与用户建立了连接之后为每个专门的用户`新生成的套接字`，可以有多个


# 运（传）输层

运输层协议为在不同主机上的`应用进程`之间提供了`逻辑通信`功能

运输层协议是在`端系统中`而不是在路由器中实现的

运输层在一次会话中承担的任务如下：

- 1.在发送端，运输层将从应用程序接收到的报文转换成运输层分组（`报文段`），一种方法是将报文划分为较小的块，再为每一块加上一个`运输层首部`以生成运输层报文段
- 2.然后在发送端系统中，运输层将报文段传递给`网络层`，网络层将其封装成网络层分组（`数据报`）并向目的地发送（注意网络路由器只作用于网络层分组，不检查运输层报文段的字段）
- 3.在接收端，网络层从数据报中提取运输层报文段，传递给运输层，运输层再处理报文段，将数据传递给应用程序

## 运输层与网络层的关系

网络层提供的是不同`主机`之间的逻辑通信，而运输层提供的是不同主机上的`应用进程`之间的逻辑通信

运输层协议能够提供的服务常常受制于底层网络层协议的服务模型

## 多路复用与多路分解

多路复用与多路分解就是将由网络层提供的`主机到主机`交付服务延伸到为运行在主机上的应用程序提供`进程到进程`的交付服务

接收主机中的运输层实际上并没有直接将数据交付给进程，而是将数据交给了一个中间的`套接字`

- 在接收端，将运输层报文段中的数据交付到正确的套接字的工作称为`多路分解`
- 在源主机，从不同套接字中收集数据块，并为每个数据块封装首部信息从而生成报文段，然后将报文段传递到网络层，所有这些工作称为`多路复用`

在运输层报文段中含有`源端口号字段`和`目的端口号字段`（每个端口号字段16位）

### UDP连接中的多路复用与多路分解

一个UDP套接字是由一个`二元组`标识的，它包含一个目的IP地址和一个目的端口号

运输层根据目的端口号将报文段交付给对应的套接字

### TCP连接中的多路复用与多路分解

一个TCP套接字是由一个`四元组`标识的，它包含源IP地址、源端口号、目的IP地址和目的端口号

运输层根据所有4个字段来定向到相应的套接字

## 无连接运输 UDP

UDP协议可以看作只是为网络层协议增加了`复用/分解`功能和少量的`差错检测`

UDP相对于TCP的优势：

- 1.关于发送什么数据以及何时发送的`应用层控制`更为精细，因为UDP几乎不对传输进行限制，诸如拥塞控制等
- 2.无需连接建立，能够节省时间
- 3.无连接状态，能够省去维护连接的资源消耗
- 4.分组首部开销小，TCP报文段首部是`20字节`，而UDP是`8字节`

### UDP报文

UDP报文段的首部有`4个字段`，分别为`源端口号`、`目的端口号`、`长度`和`校验和`每个字段`2字节`

源端口号在返回响应时使用，目的端口号在进行多路分解时使用，长度字段只是了UDP报文段中的`字节数（首部加数据）`，校验和用来检测数据是否出现了差错

### UDP校验和

校验和用于检测报文段从源到目的移动时，其中的比特是否发生了改变

发送方的UDP对报文段的所有`16比特的字的和`进行`反码`运算，得到校验和（可以看一下书上P133的例子）

最终在接收端，所有的16比特字（包括校验和）加在一起应该是`0xffff`

## 可靠数据传输原理

通过可靠数据传输协议，传输的数据比特不会受到损坏或丢失，而且所有数据都是按照发送顺序进行交付

### 一个可靠数据传输模型

- 1.自动重传请求（Automatic Repeat reQuest ARQ）协议

接收方向发送方返回确认信息，`肯定确认（ACK）`表示当前分组被正确接收，`否定确认（NAK）`表示当前分组有误并需要`重新发送`

ARQ协议需要实现三个功能：`差错检测`、`接收方反馈`和`重传`

注意当发送方处于等待ACK或NAK的状态时，它`不能继续从上层获得数据`，称之为`停等协议`

- 2.分组序号

在ARQ协议中，如果ACK或NAK分组受损，发送方将无法判断数据发送情况

为解决这个问题，使用最广泛的方法是在数据分组中添加一个新的字段，让发送方对数据分组`编号`，并发送其`序号`（分组序号在0和1之间交替，如果出现`相邻的0或1`则认为后面的分组是`重传`）

- 3.丢包

解决丢包问题的关键是`怎样检测丢包`以及`发生丢包之后该做什么`

实践中采取的方法是发送方设定一个`时间`，如果在这个时间内没有收到ACK，则认为发生了丢包，`重传`该分组

发送方应该做到：

- 1.每次发送一个数据分组，便启动一个定时器
- 2.响应定时器中断
- 3.终止定时器

可以看出这种模型的重点有三：`应答`、`序号`和`超时`

*书上P142图*

### 流水线可靠数据传输协议

前面介绍的可靠数据传输协议有一个缺点，就是它使用`停等协议`，这意味着发送方在等到接收方的应答之前什么都做不了，这会大大降低发送方的利用率

解决这个问题的方法是：允许发送方连续发送个多个分组而`无需等待确认`，因为这些分组可以视为被添加到一条流水线中，所以也称为`流水线技术`

而为了在流水线技术上实现可靠数据传输，还需要实现以下功能：

- 1.增加序号范围
- 2.发送方和接收方两端需要缓存多个分组
- 3.差错恢复，有两种基本方法：`回退N步`和`选择重传`

#### 回退N步 （Go-Back-N GBN）

GBN协议也被称为`滑动窗口协议`，因为它基于`分组的序号`一个长度为N的窗口，窗口的左端点称为`基序号base`（表示最`早未确认分组`的序号）；
在窗口中还有一个`下一个序号nextseqnum`（表示`最小的未使用序号`）

这几个端点将序号切分为4段

- 1.`0, base-1` 表示已发送并被确认的分组（窗口外）
- 2.`base, nextseqnum-1` 表示已发送但未被确认的分组（窗口内）
- 3.`nexyseqnum, base+N-1` 表示将立即被发送的分组（窗口内）
- 4.`base+N以外` 表示暂时不能使用的分组（窗口外）

有了窗口的概念，就可以描述GBN的过程

在发送方需要响应三种类型的事件：

- 1.`上层的调用` 当窗口已满时，发送方只需将数据返回给上层，隐式的告诉上层该窗口已满
- 2.`接收到ACK` 在GBN中对序号为n的分组采取`积累确认`方式，即当接收到序号为n的确认响应时，表示接收方已经正确接收到`所有序号n以前（包括n）`的分组
- 3.`超时` 发送方将重传所有已发送但未确认的分组（`base, nextseqnum-1`）

在接收方，如果一个序号为n的分组被正确接收，则接收方为`分组n`发送一个ACK，并将数据交付上层，在所有其他情况下，接收方`丢弃`该分组

接收方不必缓存任何分组，因为发送方会重传

#### 选择重传 （Selective Repeat SR）

使用GBN协议时，有时一个分组的差错会引起GBN`重传大量分组`，而很多分组是没有必要重传的

通过SR协议能够让发送方仅重传那些`它怀疑在接收方出错的分组`而避免了不必要的重传；这种个别、按需的重传需要接收方`逐个地`确认正确接收的分组

在SR协议中，依然使用长度为N的窗口，区别是发送方已经收到了`窗口中某些分组的ACK`

发送方需要执行的操作：

- 1.`从上层接收到数据` 与GBN类似
- 2.`收到ACK` 如果收到的ACK分组序号在窗口内，则发送方将该分组标记为已接受，如果分组的序号为base（窗口的起始点）则窗口右移到具有`最小序号的未确认分组处`，若窗口移动了并且有`序号落在窗口内的未发送分组`，则发送这些分组
- 3.`超时` 与GBN类似

接收方：

- 1.`窗口内的序号被正确接收` 向发送方返回一个ACK，如果该分组以前没接受过，则`缓存该分组`，如果该分组的序号等于窗口基序号，则将`该分组以前`缓存的`序号连续`的分组交付给上层，然后接收窗口按向右移动的分组的编号向上层交付（其实就是将`新的基序号之前`的分组上传）
- 2.`序号在前面一个窗口长度之内的分组（[base-N, base-1]）被正确收到` 返回一个ACK，应答非窗口内的分组的目的是让`发送方`知道这些分组已经被正确传输
- 3.其他情况下忽略当前分组

实践中，窗口长度必须小于或等于`序号空间`大小的一半

可以看出，流水线可靠数据传输的主要实现技术有：`窗口（积累确认）`、`缓存`和`超时`

*这一部分可以看一下书P148*


## 面向连接的运输 TCP

TCP是面向连接的，因为在一个应用进程可以开始向另一个应用进程发送数据之前，两个`进程`必须先`握手`

TCP是`双向的`（书库可以从进程A流向进程B，也可以从B流向A）、`点对点的`（TCP只能是单个发送方与单个接收方之间的连接）

简单描述TCP连接的建立：客户首先发送报文段1，服务器用报文段2来响应，最后客户用报文段3响应，前两个报文段`不包含应用层数据`，而第三个报文段包含。这种连接建立过程被称为`三次握手`

一些概念：

- 1.发送缓存：发送缓存是三次握手期间设置的，TCP发送时，会在发送缓存中取出数据，传递给网络层
- 2.接收缓存：同样是三次握手期间设置的，接收方的应用程序在接收缓存中读取数据流（TCP连接的每一段都有`各自的`接收和发送缓存）
- 3.最大报文长度（Maximum Segment Size MSS）：TCP可以`从缓存中取出并放入报文段`的最大数据量，而MSS的确定通常由本地发送主机的最大链路层帧长度（或最大传输单元 Maximum Transmission Unit `MTU`）来设置

TCP连接的组成在端主机上包括`缓存`、`变量`和`套接字`

### TCP报文段结构

TCP报文段包含首部和数据字段，其中首部一般是`20字节`，它包含以下几个部分：

- 1.源端口号（16位）
- 2.目的端口号（16位）
- 3.检验和（16位）
- 4.序号（32位）
- 5.确认号（32位）
- 6.接收窗口（16位），用于指示接收方愿意接收的字节数量
- 7.首部长度（4位），指示了以`32位的字`为单位的TCP首部长度
- 8.标志字段（6位），包含一些标志位ACK（应答）；RST、SYN、FIN（用于连接建立和拆除）、CWR、ECE（用于明确拥塞通告）、PSH（指示接收方将数据交付上层）、URG（指示发送端的`被上层指示为紧急`的数据） 标志字段和首部长度字段有一些保留位，它们三个`合在一起有16位`
- 9.紧急数据指针字段（16位
- 10.选项字段（可选并可变长），用作发送方与接收方协商最大报文长度时，或在高速网络环境下用作窗口调节因子，`通常为空`

实践中PSH、URG和紧急数据指针`没有使用`

#### 序号和确认号

TCP将数据看作一个无结构的、有序的`字节流`，而一个报文段的序号是该报文段`首字节的字节流编号`

比如一个5000字节的文件，MSS为100字节，TCP会为该数据流创建50个报文段，第一个报文段分配序号0，第二个分配序号100，以此类推。每一个序号被填入到对应TCP报文段首部的序号字段中

而对于确认号来说，主机A填充进报文段的确认号是主机A`期望从主机B接收到的下一字节`的序号

假设主机A已经接收到主机B的编号为0-100的所有字节，那它向主机B发送的下一个报文段中确认号就是101

事实上，TCP连接的双方可以`随机的选择初始序号`，不必为0

#### 往返时间的估计与超时

报文段的样本RTT（SampleRTT）表示从某段报文段被发出到对该报文段的确认收到（一个来回）之间的时间

在任意时刻，只为一个`已发送但未被确认`的报文段估计SampleRTT

为使SampleRTT具有代表性，TCP维持一个SampleRTT均值（EstimatedRTT），它是加权平均算得的，计算公式为：

```
EstimatedRTT = (1-α)*EstimatedRTT + α*SampleRTT
```

官方给出的α推荐值为`0.125`

这种加权平均方法被称为`指数加权移动平均`（Exponential Weighted Moving Average EWMA）对最近的样本赋予的权值要`大于`对旧样本赋予的权值

同时还给出了RTT偏差（DevRTT）用于估算SampleRTT一般会偏离EstimatedRTT的程度，它的计算公式为：

```
DevRTT = (1-β)*DevRTT + β*|SampleRTT - EstimatedRTT|
```

β的推荐值为`0.25`

根据上面的一些概念，可以设定重传超时间隔的算法：

```
TimeoutInterval = EstimatedRTT + 4*DevRTT
```

TimeoutInterval的初始推荐值为`1秒`，当出现超时后，TimeoutInterval会`加倍`，当后续的传输受到EstimatedRTT后，将使用公式计算TimeoutInterval

### TCP的可靠数据传输

TCP的可靠数据传输服务确保一个进程从其接收缓存中读出的数据是`无损坏`、`无间隙`、`非冗余`和`按序`的数据流

TCP发送方有三个主要的事件：接收上层数据、定时器超时和接收ACK

- 1.接收到上层数据时如果定时器没有运行就启动定时器，并将数据包装后发给IP
- 2.如果发生定时器超时，就重传引起超时的报文段，然后`重启定时器`
- 3.收到ACK，将ACK包含的序号（y）与自身的状态变量中保存的序号（SendBase 最早未被确认的字节序号）进行比较，如果y > SendBase，证明y之前所有的数据（包括SendBase）都已经被确认，发送方需要更新SendBase变量。如果发送方有未确认的报文段，则还需`重启定时器`

#### 超时间隔加倍

TCP重传既有最小序号的还未被确认的报文段，但是每次重传时都会将下一次的超时间隔设置为先前值的`两倍`，而不是使用EstimatedRTT和DevRTT计算出的值

这种情况会一直持续到`收到上层应用的数据`或`收到ACK`时，此时TimeoutInterval将由最近的EstimatedRTT和DevRTT计算得出

#### 快速重传

假如TCP的接收方收到了一个序号`大于`下一个所期望的、按序的报文段，这意味着有中间的数据丢失，此时TCP将返回对`最后一个按序字节数据的重复确认`，这称为`冗余ACK`

当TCP接收方接收到对相同数据的`三个冗余ACK`，就说明这个ACK对应的报文段之后的报文段已经丢失，此时TCP将执行`快速重传`，即在该报文段的`定时器过期之前`重传丢失的报文段

#### 回退N步+选择重传

TCP的差错恢复机制相当于GBN和SR的混合

### 流量控制

在接收方数据先被放入`接收缓存`中，然后应用程序从接收缓存读取数据，如果应用程序读取的速度小于发送方的发送速度，则会引起`缓存溢出`

为了解决这个问题，TCP提供了`流量控制服务`，它是一个`速度匹配`服务，即将发送方的发送速度与接收方应用程序的读取速度相匹配

（区别于`拥塞控制`：拥塞控制指的是TCP发送方因为`IP网络`的拥塞而被遏制）

TCP通过让`发送方`维护一个称为`接收窗口`的变量来提供流量控制，它的作用是告诉发送方接收方还有多少可用的缓存空间

定义变量：

- LastByteRead：接收方的应用进程从`接收缓存读出`的数据流的`最后一个字节`编号
- LastByteRcvd：已经`放入接收方接收缓存`的数据流的`最后一个字节`编号
- RcvBuffer：接收缓存长度

因为接收缓存不许溢出，则下式必须成立

```
LastByteRcvd - LastByteRead <= RcvBuffer
```

则接收窗口rwnd为：

```
rwnd = RcvBuffer - (LastByteRcvd - LastByteRead)
```

接收方将当前rwnd放入报文段的`接收窗口字段`中，来告诉发送方自己还有多少缓存空间可用

在发送方也有两个变量：

- LastByteSend：最后发送出的字节编号
- LastByteAcked：最后被确认的字节编号

`LastByteSend - LastByteAcked`则表示已发出但未被确认的数据量，需要将它控制在rwnd之内，即：

```
LastByteSend - LastByteAcked <= rwnd
```

- 注意在接收窗口为0时，为`防止发送方被拥塞`，发送方需要继续发送只有`一个字节`数据的报文段（因为接收方只能在返回响应的时候才能将新的接收窗口告诉发送方）

### TCP连接管理

#### 连接的建立（三次握手）

- 1.客户向服务器发送一个不包含数据的报文段，其中的`SYN标志位置1`，并且随机生成一个`初始序号`（client_isn），放置于报文段的`序号字段`中。这个特殊报文段被称为`SYN报文段`

- 2.服务器收到TCP SYN报文段，为该TCP连接分配缓存和变量（这容易收到SYN洪泛攻击，后面会讨论），并向客户返回一个`允许连接`的报文段，这个报文段包含三个重要的信息：`SYN置1`、`确认号字段为client_isn + 1`以及服务器生成自己的`初始序号（server_isn）放在序号字段中`。该报文段称为`SYNACK报文段`

- 3.客户收到SYNACK报文段后，为TCP连接分配缓存和变量，并向服务器发送一个`确认报文段`，其`确认号`字段设置为`server_isn + 1`，因为此时连接已经建立，`SYN被置为0`，并且此次传输可以`发送数据`

如果服务器上的某端口未开启，则向客户发送一个特殊重置报文段，其中`RST标志位置1`，来告诉客户当前请求的服务未开启

#### 连接的终止

TCP连接的`任意一方`都可以终止连接，以客户终止为例：

- 1.客户应用进程发送一个关闭连接命令，使得客户的TCP向服务器发送一个特殊的TCP报文段，其中首部的`FIN标志位置1`

- 2.服务器收到报文段后，先向发送方返回一个`确认报文段`；然后服务器发送自己的`终止报文段`，其中的`FIN置1`（注意发送了两次）

- 3.客户对服务器的终止报文段返回一个`确认`，此时连接终止

#### SYN洪泛攻击

SYN洪泛攻击指的是攻击者发送大量的TCP SYN报文段（第一次握手），却`不完成对服务器的确认`（第三次握手），由于服务器在第二次握手的时候就分配了资源，这将使得服务器的资源被消耗殆尽

解决办法是使用`SYN cookie`技术：服务器接收到SYN报文段时，暂时不会分配资源，而是针对该报文段的源、目的IP地址与端口号生成一个`初始TCP序列号`，称为cookie，并将它返回给客户，客户发送确认信息时将包含这个cookie，从而验证该用户是一个合法用户


## 拥塞控制原理

引起拥塞控制的原因是有太多的源想以过高的速率发送数据，为了处理网络拥塞，需要一些机制在面临网络拥塞时`遏制发送方`

引起网络拥塞有几种因素：

- 1.多个发送方竞争链路资源，假设一个共享链路的容量为R，如果有两个发送方，则它们的吞吐量最多为R/2，而且吞吐量越接近链路容量，就需要经历越大的`排队时延`

- 2.路由器缓存有限，分组到达一个已满的缓存将被丢弃，此时发送方必须重传以补偿`因为缓存溢出而被丢弃`的分组

且因为超时机制的存在，发送方可能会`提前发生超时`并重传在队列中已经被推迟的但还`未丢失的分组`，此时就会使得路由器利用链路带宽来发送`不必要的分组副本`

- 3.多个距离不同的发送方经过相同的路由器，`速率高的那一组传输将占用大部分的资源`，当处于重载的情况下，速率低的一方吞吐量可能趋于0

#### 拥塞控制方法

根据`网络层是否为拥塞控制提供了帮助`，可以将拥塞控制分为两类：

- 1.端到端拥塞控制：网络层没有提供支持，即使存在拥塞，端系统必须通过对网络行为的观察（如分组丢失与时延）来推断之。TCP就是使用这种方法

- 2.网络辅助的拥塞控制：路由器向发送方提供关于拥塞状态的`显示反馈信息`（直接发给发送方或通过接收方返回给发送方）


## TCP拥塞控制

TCP所采用的拥塞控制方法是端到端控制，即`发送端`通过感知网络拥塞程度来`限制`其发送速率

### 速率控制

在TCP的发送方，拥塞控制机制跟踪一个`拥塞窗口（cwnd）`变量。在发送方中为被确认的数据量不能超过接收窗口与拥塞窗口的最小值，即

```
LastByteSent - LastByteAcked <= min(cwnd, rwnd)
```

因此发送方的发送速率大概是`cwnd/RTT 字节/秒`，通过调节cwnd的值，可以控制发送速率

### 拥塞感知

将TCP发送方的“丢包事件”定义为：`出现超时`或`收到3个冗余ACK`

当出现丢包事件，则认为网络中存在拥塞，将减小传输速率

### TCP拥塞控制算法

TCP拥塞控制算法有三个主要部分：慢启动、拥塞避免和快速回复

#### 1.慢启动

在慢启动状态，cwnd的初始值为1个MSS，并且每当传输的报文段`首次确认`就将窗口长度变为`2倍`，所以慢启动阶段窗口以指数增长

有几种情况可以结束慢启动：

- 1.当出现一个由`超时指示`的丢包事件时，发送方将`cwnd设置为1`并`重新开始慢启动`过程

并且将`慢启动阈值 ssthresh`设置为`当前的cwnd/2`

- 2.当cwnd的值`等于ssthresh`时，结束慢启动并`转移到拥塞避免`模式

- 3.如果检测到`3个冗余ACK`，TCP执行`快速重传`并进入`快速恢复状态`

#### 2.拥塞避免

进入拥塞避免状态时，cwnd的值大约是`上次遇到拥塞的值的一半`，所以距离拥塞可能并不遥远，因此要采取谨慎的方式增加窗口

在拥塞避免状态中，每个RTT只将cwnd的值增加`一个MSS`

有几种情况可以结束拥塞避免状态：

- 1.当出现`超时`时，与慢启动相同，价格cwnd设置为`一个MSS`，当出现`超时指示的丢包`时，ssthresh被设置为`当前cwnd的一半`，进入`慢启动状态`

- 2.出现3个冗余ACK时，将ssthresh设为`cwnd的一半`，然后将`cwnd减半`（优化的方法是减半后加上3个冗余ACK带来的3个MSS），进入`快速恢复状态`

#### 3.快速恢复

有两种情况：

- 1.对于引起TCP进入快速恢复状态的缺失报文段，收到的每一个ACK，cwnd`增加一个MSS`。最终当缺失报文段的ACK到达时，TCP将`cwnd设置为ssthresh的值`并进入`拥塞避免状态`

- 2.出现超时的时候，cwnd设为`一个MSS`，ssthresh设为`cwnd值的一半`，并进入`慢启动状态`


#### 其他特性

如果忽略慢启动状态（因为很短暂），cwnd的增加是加法（每个RTT增加一个MSS），而降低是乘法（减半）

所以TCP拥塞控制被称为`加性增、乘性减（Additive-Increase, Multiplicative-Decrease, AIMD）`拥塞控制方式

- TCP吞吐量

理想条件下：一条连接的平均吞吐量等于`0.75*W/RTT`，其中W为拥塞窗口长度

演化后：一条连接的平均吞吐量等于`1.22*MSS/(RTT*sqrt(L))`，其中L为丢包率

可以看出要想获得大的吞吐量，丢包率必须很小


### 公平性

`瓶颈链路`：在一个连接中，沿着该连接路径上的所有其他段链路都不拥塞，而且其他链路都比瓶颈链路有更充足的容量

假设K条TCP连接，每一条都经过一段速率为R的瓶颈链路，如果每条连接的平均传输速率接近`R/K`，则认为该`拥塞控制机制`是`公平的`

TCP的AIMD控制方法中，每条连接实现的带宽最终将沿着平等带宽共享曲线波动，所以TCP的拥塞控制是`趋于公平的`（书P183）

#### 公平性和UDP

因为UDP没有拥塞控制，所以在TCP的角度，UDP是`不公平的`，TCP的拥塞控制在面临拥塞时，会降低传输速率，而UDP不会，所以UDP源有可能`压制TCP流量`

#### 公平性和并行TCP连接

当一个应用使用多条并行连接时（通常是传输一个Web页面的多个对象），它将占用一条拥塞链路中较大比例的带宽

比如一个速率为R且当前有9个连接的链路，如果一个新的应用加入，并且使用一条TCP连接的话，他将得到`R/10`的速率；但如果它使用11条并行TCP连接，这个应用就会得到`11*R/20`的速率

### 网络辅助拥塞控制：明确拥塞通告

简单介绍一种不同于TCP端到端拥塞控制的方法：`明确拥塞通告（Explicit Congestion Notification ECN）`，它使用网络辅助拥塞控制方式

它使用网络层`IP数据报首部的两个比特`作为拥塞指示，首先发送给接收主机，接收主机在TCP ACK报文段中设置`ECE（明确拥塞通告回显）比特`，告知发送主机的TCP发生了拥塞


# 网络层：数据平面

网络层可以被分为两个互相作用的部分：`数据平面`和`控制平面`

- 数据平面：指的是`路由器`的功能，它决定到达路由器输入链路之一的数据报如何`转发`到该路由器的输出链路之一，数据平面中的是`本地动作`，通常由`硬件实现`

- 控制平面：指的是`网络范围`的逻辑，它控制数据报沿着从源主机到目的主机的端到端路径中路由器之间的`路由方式（路由选择）`，通常由`软件实现`

路由器中有一个关键元素是`转发表`，路由器通过检查到达分组首部的一个或多个字段值，并使用这些首部值在`转发表中索引`，来确定应该将分组转发到哪条输出链路上去。

那么转发表是如何获得的呢？

- 1.传统方法：一台路由器中的`路由选择算法`与`其他路由器中的路由选择算法`通信，从而计算出转发表的值

- 2.控制平面中的`SDN`方法：由一个`远程控制器`计算和分发转发表供所有路由器使用。这被称为`软件定义网络（Software-Defined Networking SDN）`，因为远程控制器是用软件实现的

因特网的网络层提供了`尽力而为服务`，即不保证交付、按序交付、端到端时延以及最小带宽等，相当于不提供服务

## 路由器工作原理

路由器由4个组件构成：

- 1.输入端口，它有3个层次：
    - 1.最靠外的层次，执行物理层功能
    - 2.中间层次：执行链路层功能
    - 3.最靠内的层次：执行`查找`功能，通过查询转发表决定路由器的输出端口（将通过交换结构转发到输出端口）

- 2.交换结构。将路由器的输入端口连接到它的输出端口，交换结构完全包含在路由器内部，是`路由器中的网络`

- 3.输出端口，与输入端口类似，也有3个从外到内的层次。而且如果一个链路是双向时，输出端口与输入端口通常`成对`出现在同一线路卡上

- 4.路由选择处理器，执行`控制平面功能`

注意路由器中的输入端口、输出端口与交换结构全部通过`硬件`实现，因为要实现纳秒级的数据处理

### 输入端口处理和基于目的转发

输入端口需要执行的功能有：

- 1.查找（最重要的功能）
- 2.物理层和链路层处理
- 3.检查分组的版本号、检验和于寿命字段，并重写后两个字段
- 4.更新用于网络管理的计数器

其中查找使用的传发表是通过路由选择处理器来进行计算和更新，或接收远程SDN控制器的内容

转发表从路由选择处理器经过`独立总线`复制到线路卡，这样无须基于每个分组调用几种式路由选择处理器

那么如何确定转发的输出端口呢？对于32位的IP地址，不可能为每一种情况都分配表项

通常的做法是`前缀匹配`，即一个固定的前缀能够对应一组IP地址，而它们`指向相同的表项`，当存在一个IP地址匹配多个前缀时，路由器使用`最长前缀匹配规则`

路由器中对转发表的查找由`硬件实现`，通常使用`三态内容可寻址存储器`来查找

### 交换方式

分组需要经过交换结构才能到达输出端口，有几种常用的交换方式：

- 1.经内存交换：分组首先从输入端口被复制到路由选择处理器`内存`中，路由选择处理器从其首部中提取1目的地址，在转发表中查找合适的输出端口，并将分组复制到输出端口的`缓存`中

- 2.经总线交换：输入端口预先为分组增加一个`交换机内部标签首部`，分组经总线被`所有`输出端口接收，但只有与标签匹配的端口能够保存

- 3.经互联网络交换（交叉总线）：可以`并行`转发多个分组，这种方式是`非阻塞`的

### 排队

排队现象有可能出现在以下2个位置：

- 1.输入端口处：如果交换结构的处理速度不够快，就会在输入端口出现排队，比如两个分组经由不同的输入端口发往`同一输出端口`，后面的分组就要等待，以及`线路前部阻塞`（书P210）

- 2.输出端口处：因为输出端口在一个单位时间智能传输一个分组，如果同时有多个分组到达，就需要排队，如果排队的数量足够大，就会耗尽输出端口的可用内存，此时有两种可能：`丢弃新到达的分组`或`删除队列中的分组`

也可以在`缓存填满之前`丢弃一个分组，这可以向发送方提供一个`拥塞信号`，这种策略称为`主动队列管理`

### 分组调度

输出端口通过分组调度来在排队分组中选择一个分组进行传输，有以下几种方式：

- 1.先入先出

FIFO（或先来先服务 FCFS）规则按照到达输出链路队列的相同次序来选择分组在链路上传输

- 2.优先权排队

当需要选择分组时，优先权排队规则从队列为`非空`的`最高优先权类`中传输一个分组，在同一优先权类的分组之间通常以FIFO方式完成

注意在`非抢占式优先权排队`规则下，一旦分组开始传输，就`不会被打断`，即使到来了优先权更高的分组

- 3.循环排队

将分组分类，但没有优先级，循环调度器在这些类之间`轮流提供服务`

比如有两个类，则将按照类1，类2，类1，类2...的顺序

- 4.加权公平排队

选择方式与循环排队一样，但每个类i都有一个权wi，每个类能够分配到带宽的`wi/(∑wi)`部分

这样可以使每个类在任何时间间隔内收到`不同数量`的服务


## IP协议

### IPv4数据报

IPv4数据报的首部字段有几个关键部分：

- 1.版本号，4比特，它规定了数据报的IP协议版本

- 2.首部长度，4比特，因为数据报中可能包含一些可变的选项，所以需要首部长度来确定`数据实际开始的地方`。多数IP数据报不包含可变选项，通常的首部长度是`20字节`

- 3.服务类型，8比特，用来区分不同类型的数据报，例如有些数据报要求低时延、高吞吐量和可靠性

- 4.数据报长度，16比特，IP数据报（首部+数据）的总长度，单位是`字节`，通常数据报不会超过1500字节

- 5.16比特标识、3比特标志、13比特片偏移，他们与`IP分片`有关

- 6.寿命（TTL）， 8比特，用来确保数据报`不会永远在网络中循环`，每有一台路由器处理数据报，TTL减1，当TTL为0时，该数据包需要被`丢弃`

- 7.上层协议，8比特，指示数据报的数据部分应该交给哪个特定的`运输层协议`（类似运输层报文段中的端口号，都是指示目的地）

- 8.首部检验和，16比特，用于差错检测，方法是将首部中的每`两个字节`当作一个数，用`反码算数`进行求和

路由器一般会`丢弃`出错的数据报，并且在每台路由器上都要`重新计算`检验和并覆盖，因为TTL以及可变选项字段`可能会改变`

- 9.源、目的IP地址，各32比特

- 10.可变选项，通常很少使用

#### IPv4数据报分片

因为IP数据报被封装在链路层帧中传输，所以链路层的最大传送单元（Maximum Transmission Unit MTU）限制了IP数据报的长度，如果IP数据报长度比MTU大，就需要进行`分片`

分片重组操作都是端系统进行的，即目的主机，路由器`不参与`重组操作

为了使目的主机能够正确的重组分片，在IP数据报首部中设置了`标识`、`标志`和`片偏移`三个字段

- 1.标识，同属一个数据报的片具有相同的标识，当路由器对一个数据报分片时，相同数据报的每个片具有相同的`源地址`、`目的地址`和`标识号`，目的主机根据它们来重组

- 2.标志，由于IP是不可靠服务，片可能丢失，为了让目的主机确信收到了数据报的最后一个片，将最后一个片的标志设为`0`，其余所有片的标志为`1`

- 3.片偏移，为使目的主机能够确认是否丢失片，并能按顺序重组片，使用片偏移字段指示该片`位于初始IP数据报的哪个位置`

### IPv4编址

通常一台主机只有`一条链路`连接到网络，而路由器有多条链路，主机与物理链路的边界叫做`接口`

IP要求每台主机和路由器的`接口`拥有自己的IP地址，也就是说IP地址与接口相关联，而不与主机和和路由器相关联

IP地址采用点分十进制记忆法，如135.32.216.9，一个接口的IP地址的一部分需要由其连接的`子网`决定

#### 子网

通常，多台由`以太网互联的主机接口`与`一个路由器接口`构成一个子网，它们拥有一段共同的IP地址，比如两台主机的地址为223.1.1.1和223.1.1.2，路由器接口的地址为223.1.1.3，这个子网的地址记为`223.1.1.0/24`，其中的`/24`记法称为`子网掩码`，指示32比特中最左侧24比特定义了子网地址

不只是主机和路由器之间构成子网，`两个路由器接口`之间也可以构成子网

可以视作每个`路由器的接口`是一个端点，每个`以太网互联的主机`有一个端点，而用`端点隔开`的网络每一个部分都是一个子网

#### 地址分配

早期的IP地址分配采用`分类编址`，即子网掩码只有/8、/16和/24，但它的局限性很大，一个/24子网只能容纳`2^8-2=254`台主机（有两个特殊地址），而/16子网能容纳65534台主机，分配起来很不灵活

于是后来出现了`无类别域间路由选择（Classless Interdomain Routing CIDR）`，在CIDR中a.b.c.d/x中的x可以是小于32的任何数，分配起来更灵活

a.b.c.d/x的方式将IP地址分为两部分，X表示的高位比特称为`网络部分`，或称为`网络前缀`，一个组织通常被分配拥有相同前缀的一段地址，组织外的路由器进行传输时`只考虑前缀比特x`，这种使用单个网络前缀通告多个网络的能力称为`地址聚合`

如果被分配在200.23.16.0/20中的一个组织200.23.18.0/23需要与外部相连，那么除了向外通告200.23.16.0/20之外，还要通告200.23.18.0/23，其他路由器建立传输时，会采用`最长前缀匹配`的方式

一个IP地址的剩余32-x低位部分是用于`区分组织内部设备`的，只有组织内部的路由器转发分组时才会考虑这些比特

有一个特殊的地址`255.255.255.255`，称为IP广播地址，当一个主机发出目的地址为255.255.255.255的数据报时，该数据报会转发给同一个网络中的`所有主机`

#### 获取主机地址：动态主机配置协议

一个组织在权威机构获取到一块地址，然后可以为组织内的主机和路由器接口逐个分配IP地址

路由器的地址通常手动配置，而主机的地址则通常由`动态主机配置协议（Dynamic Host Configuration Protocal DHCP）`配置

DHCP是一种`即插即用`协议，即主机可以频繁的连接与断开，地址会自动分配

DHCP也是一个客户-服务器协议，客户是新到达得主机，每个子网具有一台DHCP服务器或有一台路由器充当DHCP`中继代理`（它能够连接到DHCP服务器），DHCP为主机分配地址的步骤如下：

- 1.DHCP服务器发现：新到达的主机首先需要发现一个能与其交互的DHCP服务器。实现方法是发送`DHCP发现报文`，客户主机在`UDP`分组中向`端口67`发送该报文

由于主机不知道目的地址，所以使用广播目的地址`255.255.255.255`并且使用“本主机”源IP地址`0.0.0.0`，链路层能够将该数据帧广播到所有该子网连接的节点

- 2.DHCP服务器提供：DHCP服务器接收到DHCP发现报文时，用`DHCP提供报文`作为响应，且仍然使用广播地址`255.255.255.255`，报文中包含收到的发现报文的`事务ID`，向客户推荐的`IP地址`，`网络掩码`以及`IP地址租用期`

- 3.DHCP请求，子网中可能存在多个DHCP服务器，主机从中选择一个，并向选中的服务器发送`DHCP请求报文`，回显配置参数

- 4.DHCP ACK：服务器用`DHCP ACK报文`对DHCP请求报文进行响应，证实所要求的参数

一旦客户主机收到DHCP ACK报文，交互就完成了，且客户能够在租用期内使用DHCP服务器分配的IP地址
